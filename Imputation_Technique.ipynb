{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imputation_Technique.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BindiyaB/DataSciencePractice/blob/master/Imputation_Technique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TCI7yZtnspj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fancyimpute import KNN, NuclearNormMinimization, SoftImpute, BiScaler\n",
        "from sklearn.datasets import load_boston\n",
        "import numpy as np\n",
        "# https://pypi.org/project/fancyimpute/\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f76rp-0en4ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boston = load_boston()\n",
        "X=boston.data\n",
        "Y=boston.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yGBzdfpq2nc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "12ed31c1-e216-4632-ba23-1193bfafd19b"
      },
      "source": [
        "X.shape, Y.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((506, 13), (506,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1CJJ6Jqq5UF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "4a6890a8-086f-4fe5-9b42-97408573744b"
      },
      "source": [
        "boston.DESCR"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4t_hsvtq8ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=X.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HMao6RB1NkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.ravel()[np.random.choice(X.size, 10, replace=False)] = np.nan # Randomly make 10 values as missing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YBwGNFT1QqT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "8b02a99a-7637-4952-faea-7d3cf42829b3"
      },
      "source": [
        "X_filled_knn = KNN(k=3).fit_transform(X)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imputing row 1/506 with 0 missing, elapsed time: 0.057\n",
            "Imputing row 101/506 with 0 missing, elapsed time: 0.057\n",
            "Imputing row 201/506 with 0 missing, elapsed time: 0.058\n",
            "Imputing row 301/506 with 0 missing, elapsed time: 0.058\n",
            "Imputing row 401/506 with 0 missing, elapsed time: 0.058\n",
            "Imputing row 501/506 with 0 missing, elapsed time: 0.059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrMaakdb1dRC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "046c1f30-3001-478b-9941-9da42b636580"
      },
      "source": [
        "# matrix completion using convex optimization to find low-rank solution\n",
        "# that still matches observed values. Slow!\n",
        "X_filled_nnm = NuclearNormMinimization().fit_transform(X) #Ask-----------------------------"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------\n",
            "\tSCS v2.1.1 - Splitting Conic Solver\n",
            "\t(c) Brendan O'Donoghue, Stanford University, 2012\n",
            "----------------------------------------------------------------------------\n",
            "Lin-sys: sparse-direct, nnz in A = 180966\n",
            "eps = 1.00e-04, alpha = 1.50, max_iters = 50000, normalize = 1, scale = 1.00\n",
            "acceleration_lookback = 10, rho_x = 1.00e-03\n",
            "Variables n = 148096, constraints m = 161252\n",
            "Cones:\tprimal zero / dual free vars: 6578\n",
            "\tlinear vars: 19734\n",
            "\tsd vars: 134940, sd blks: 1\n",
            "Setup time: 2.83e-01s\n",
            "----------------------------------------------------------------------------\n",
            " Iter | pri res | dua res | rel gap | pri obj | dua obj | kap/tau | time (s)\n",
            "----------------------------------------------------------------------------\n",
            "     0| 5.20e+21  4.88e+21  1.00e+00 -8.08e+26  1.46e+26  1.98e+26  1.34e-01 \n",
            "   100| 7.77e-04  7.96e-04  2.30e-04  1.76e+04  1.76e+04  8.21e-12  3.03e+01 \n",
            "   200| 1.51e-04  1.51e-04  9.94e-06  1.76e+04  1.76e+04  3.56e-12  6.06e+01 \n",
            "   280| 2.79e-05  2.83e-05  1.41e-05  1.76e+04  1.76e+04  2.58e-11  8.50e+01 \n",
            "----------------------------------------------------------------------------\n",
            "Status: Solved\n",
            "Timing: Solve time: 8.50e+01s\n",
            "\tLin-sys: nnz in L factor: 496882, avg solve time: 3.97e-03s\n",
            "\tCones: avg projection time: 2.41e-01s\n",
            "\tAcceleration: avg step time: 4.77e-02s\n",
            "----------------------------------------------------------------------------\n",
            "Error metrics:\n",
            "dist(s, K) = 1.3682e-07, dist(y, K*) = 1.5805e-09, s'y/|s||y| = 4.1633e-13\n",
            "primal res: |Ax + s - b|_2 / (1 + |b|_2) = 2.7936e-05\n",
            "dual res:   |A'y + c|_2 / (1 + |c|_2) = 2.8271e-05\n",
            "rel gap:    |c'x + b'y| / (1 + |c'x| + |b'y|) = 1.4062e-05\n",
            "----------------------------------------------------------------------------\n",
            "c'x = 17629.9821, -b'y = 17629.4863\n",
            "============================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S94V6ek_1i8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2fd057a-c7ee-4820-e14b-bea95f458685"
      },
      "source": [
        "# Instead of solving the nuclear norm objective directly, instead\n",
        "# induce sparsity using singular value thresholding\n",
        "X_incomplete_normalized = BiScaler().fit_transform(X) #Ask ------------------------------\n",
        "X_filled_softimpute = SoftImpute().fit_transform(X_incomplete_normalized)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[BiScaler] Initial log residual value = 14.888305\n",
            "[BiScaler] Iter 1: log residual = 3.202414, log improvement ratio=11.685890\n",
            "[BiScaler] Iter 2: log residual = 2.492459, log improvement ratio=0.709956\n",
            "[BiScaler] Iter 3: log residual = 1.823053, log improvement ratio=0.669406\n",
            "[BiScaler] Iter 4: log residual = 1.181499, log improvement ratio=0.641554\n",
            "[BiScaler] Iter 5: log residual = 0.541162, log improvement ratio=0.640336\n",
            "[BiScaler] Iter 6: log residual = -0.105473, log improvement ratio=0.646635\n",
            "[BiScaler] Iter 7: log residual = -0.762242, log improvement ratio=0.656769\n",
            "[BiScaler] Iter 8: log residual = -1.429403, log improvement ratio=0.667161\n",
            "[BiScaler] Iter 9: log residual = -2.105475, log improvement ratio=0.676072\n",
            "[BiScaler] Iter 10: log residual = -2.788405, log improvement ratio=0.682929\n",
            "[BiScaler] Iter 11: log residual = -3.476161, log improvement ratio=0.687756\n",
            "[BiScaler] Iter 12: log residual = -4.166984, log improvement ratio=0.690824\n",
            "[BiScaler] Iter 13: log residual = -4.859463, log improvement ratio=0.692479\n",
            "[BiScaler] Iter 14: log residual = -5.552524, log improvement ratio=0.693061\n",
            "[BiScaler] Iter 15: log residual = -6.245395, log improvement ratio=0.692870\n",
            "[BiScaler] Iter 16: log residual = -6.937548, log improvement ratio=0.692153\n",
            "[BiScaler] Iter 17: log residual = -7.628654, log improvement ratio=0.691106\n",
            "[BiScaler] Iter 18: log residual = -8.318534, log improvement ratio=0.689879\n",
            "[BiScaler] Iter 19: log residual = -9.007117, log improvement ratio=0.688583\n",
            "[BiScaler] Iter 20: log residual = -9.694413, log improvement ratio=0.687296\n",
            "[BiScaler] Iter 21: log residual = -10.380486, log improvement ratio=0.686073\n",
            "[BiScaler] Iter 22: log residual = -11.065433, log improvement ratio=0.684947\n",
            "[BiScaler] Iter 23: log residual = -11.749372, log improvement ratio=0.683938\n",
            "[BiScaler] Iter 24: log residual = -12.432427, log improvement ratio=0.683056\n",
            "[BiScaler] Iter 25: log residual = -13.114729, log improvement ratio=0.682302\n",
            "[BiScaler] Iter 26: log residual = -13.796402, log improvement ratio=0.681673\n",
            "[BiScaler] Iter 27: log residual = -14.477563, log improvement ratio=0.681161\n",
            "[BiScaler] Iter 28: log residual = -15.158323, log improvement ratio=0.680759\n",
            "[BiScaler] Iter 29: log residual = -15.838780, log improvement ratio=0.680457\n",
            "[BiScaler] Iter 30: log residual = -16.519024, log improvement ratio=0.680244\n",
            "[BiScaler] Iter 31: log residual = -17.199135, log improvement ratio=0.680111\n",
            "[BiScaler] Iter 32: log residual = -17.879183, log improvement ratio=0.680048\n",
            "[BiScaler] Iter 33: log residual = -18.559229, log improvement ratio=0.680046\n",
            "[BiScaler] Iter 34: log residual = -19.239326, log improvement ratio=0.680097\n",
            "[BiScaler] Iter 35: log residual = -19.919518, log improvement ratio=0.680192\n",
            "[BiScaler] Iter 36: log residual = -20.599845, log improvement ratio=0.680327\n",
            "[BiScaler] Iter 37: log residual = -21.280338, log improvement ratio=0.680493\n",
            "[BiScaler] Iter 38: log residual = -21.961025, log improvement ratio=0.680687\n",
            "[BiScaler] Iter 39: log residual = -22.641927, log improvement ratio=0.680903\n",
            "[BiScaler] Iter 40: log residual = -23.323064, log improvement ratio=0.681136\n",
            "[BiScaler] Iter 41: log residual = -24.004448, log improvement ratio=0.681384\n",
            "[BiScaler] Iter 42: log residual = -24.686090, log improvement ratio=0.681643\n",
            "[BiScaler] Iter 43: log residual = -25.368000, log improvement ratio=0.681910\n",
            "[BiScaler] Iter 44: log residual = -26.050183, log improvement ratio=0.682183\n",
            "[BiScaler] Iter 45: log residual = -26.732643, log improvement ratio=0.682460\n",
            "[BiScaler] Iter 46: log residual = -27.415381, log improvement ratio=0.682738\n",
            "[BiScaler] Iter 47: log residual = -28.098398, log improvement ratio=0.683017\n",
            "[BiScaler] Iter 48: log residual = -28.781694, log improvement ratio=0.683295\n",
            "[BiScaler] Iter 49: log residual = -29.465265, log improvement ratio=0.683572\n",
            "[BiScaler] Iter 50: log residual = -30.149110, log improvement ratio=0.683845\n",
            "[BiScaler] Iter 51: log residual = -30.833225, log improvement ratio=0.684114\n",
            "[BiScaler] Iter 52: log residual = -31.517604, log improvement ratio=0.684380\n",
            "[BiScaler] Iter 53: log residual = -32.202245, log improvement ratio=0.684640\n",
            "[BiScaler] Iter 54: log residual = -32.887140, log improvement ratio=0.684896\n",
            "[BiScaler] Iter 55: log residual = -33.572286, log improvement ratio=0.685145\n",
            "[BiScaler] Iter 56: log residual = -34.257674, log improvement ratio=0.685388\n",
            "[BiScaler] Iter 57: log residual = -34.943302, log improvement ratio=0.685628\n",
            "[BiScaler] Iter 58: log residual = -35.629160, log improvement ratio=0.685858\n",
            "[BiScaler] Iter 59: log residual = -36.315243, log improvement ratio=0.686083\n",
            "[BiScaler] Iter 60: log residual = -37.001547, log improvement ratio=0.686304\n",
            "[BiScaler] Iter 61: log residual = -37.688060, log improvement ratio=0.686513\n",
            "[BiScaler] Iter 62: log residual = -38.374784, log improvement ratio=0.686723\n",
            "[BiScaler] Iter 63: log residual = -39.061706, log improvement ratio=0.686922\n",
            "[BiScaler] Iter 64: log residual = -39.748822, log improvement ratio=0.687116\n",
            "[BiScaler] Iter 65: log residual = -40.436120, log improvement ratio=0.687299\n",
            "[BiScaler] Iter 66: log residual = -41.123613, log improvement ratio=0.687493\n",
            "[BiScaler] Iter 67: log residual = -41.811262, log improvement ratio=0.687649\n",
            "[BiScaler] Iter 68: log residual = -42.499096, log improvement ratio=0.687834\n",
            "[BiScaler] Iter 69: log residual = -43.187116, log improvement ratio=0.688020\n",
            "[BiScaler] Iter 70: log residual = -43.875254, log improvement ratio=0.688138\n",
            "[BiScaler] Iter 71: log residual = -44.563551, log improvement ratio=0.688297\n",
            "[BiScaler] Iter 72: log residual = -45.251880, log improvement ratio=0.688329\n",
            "[BiScaler] Iter 73: log residual = -45.940770, log improvement ratio=0.688889\n",
            "[BiScaler] Iter 74: log residual = -46.629281, log improvement ratio=0.688512\n",
            "[BiScaler] Iter 75: log residual = -47.318046, log improvement ratio=0.688765\n",
            "[BiScaler] Iter 76: log residual = -48.007114, log improvement ratio=0.689068\n",
            "[BiScaler] Iter 77: log residual = -48.696608, log improvement ratio=0.689493\n",
            "[BiScaler] Iter 78: log residual = -49.385076, log improvement ratio=0.688468\n",
            "[BiScaler] Iter 79: log residual = -50.075405, log improvement ratio=0.690329\n",
            "[BiScaler] Iter 80: log residual = -50.764805, log improvement ratio=0.689401\n",
            "[BiScaler] Iter 81: log residual = -51.454452, log improvement ratio=0.689647\n",
            "[BiScaler] Iter 82: log residual = -52.141996, log improvement ratio=0.687544\n",
            "[BiScaler] Iter 83: log residual = -52.833303, log improvement ratio=0.691306\n",
            "[BiScaler] Iter 84: log residual = -53.520998, log improvement ratio=0.687695\n",
            "[BiScaler] Iter 85: log residual = -54.218948, log improvement ratio=0.697950\n",
            "[BiScaler] Iter 86: log residual = -54.906234, log improvement ratio=0.687286\n",
            "[BiScaler] Iter 87: log residual = -55.578817, log improvement ratio=0.672582\n",
            "[BiScaler] Iter 88: log residual = -56.290608, log improvement ratio=0.711792\n",
            "[BiScaler] Iter 89: log residual = -56.982441, log improvement ratio=0.691833\n",
            "[BiScaler] Iter 90: log residual = -57.624693, log improvement ratio=0.642252\n",
            "[BiScaler] Iter 91: log residual = -58.332549, log improvement ratio=0.707856\n",
            "[BiScaler] Iter 92: log residual = -59.030081, log improvement ratio=0.697532\n",
            "[BiScaler] Iter 93: log residual = -59.790455, log improvement ratio=0.760374\n",
            "[BiScaler] Iter 94: log residual = -60.320437, log improvement ratio=0.529982\n",
            "[BiScaler] Iter 95: log residual = -61.212952, log improvement ratio=0.892515\n",
            "[BiScaler] Iter 96: log residual = -61.918769, log improvement ratio=0.705817\n",
            "[BiScaler] Iter 97: log residual = -62.523820, log improvement ratio=0.605051\n",
            "[BiScaler] Iter 98: log residual = -62.538752, log improvement ratio=0.014931\n",
            "[BiScaler] Iter 99: log residual = -63.642051, log improvement ratio=1.103300\n",
            "[BiScaler] Iter 100: log residual = -63.696071, log improvement ratio=0.054020\n",
            "[SoftImpute] Max Singular Value of X_init = 51.546049\n",
            "[SoftImpute] Iter 1: observed MAE=0.032211 rank=12\n",
            "[SoftImpute] Iter 2: observed MAE=0.032220 rank=12\n",
            "[SoftImpute] Iter 3: observed MAE=0.032230 rank=12\n",
            "[SoftImpute] Iter 4: observed MAE=0.032242 rank=12\n",
            "[SoftImpute] Iter 5: observed MAE=0.032253 rank=12\n",
            "[SoftImpute] Iter 6: observed MAE=0.032263 rank=12\n",
            "[SoftImpute] Iter 7: observed MAE=0.032271 rank=12\n",
            "[SoftImpute] Iter 8: observed MAE=0.032279 rank=12\n",
            "[SoftImpute] Iter 9: observed MAE=0.032285 rank=12\n",
            "[SoftImpute] Iter 10: observed MAE=0.032291 rank=12\n",
            "[SoftImpute] Iter 11: observed MAE=0.032296 rank=12\n",
            "[SoftImpute] Iter 12: observed MAE=0.032300 rank=12\n",
            "[SoftImpute] Iter 13: observed MAE=0.032303 rank=12\n",
            "[SoftImpute] Iter 14: observed MAE=0.032307 rank=12\n",
            "[SoftImpute] Iter 15: observed MAE=0.032309 rank=12\n",
            "[SoftImpute] Iter 16: observed MAE=0.032312 rank=12\n",
            "[SoftImpute] Iter 17: observed MAE=0.032314 rank=12\n",
            "[SoftImpute] Iter 18: observed MAE=0.032316 rank=12\n",
            "[SoftImpute] Iter 19: observed MAE=0.032317 rank=12\n",
            "[SoftImpute] Iter 20: observed MAE=0.032318 rank=12\n",
            "[SoftImpute] Iter 21: observed MAE=0.032319 rank=12\n",
            "[SoftImpute] Iter 22: observed MAE=0.032320 rank=12\n",
            "[SoftImpute] Iter 23: observed MAE=0.032321 rank=12\n",
            "[SoftImpute] Iter 24: observed MAE=0.032322 rank=12\n",
            "[SoftImpute] Iter 25: observed MAE=0.032323 rank=12\n",
            "[SoftImpute] Iter 26: observed MAE=0.032323 rank=12\n",
            "[SoftImpute] Iter 27: observed MAE=0.032324 rank=12\n",
            "[SoftImpute] Iter 28: observed MAE=0.032324 rank=12\n",
            "[SoftImpute] Iter 29: observed MAE=0.032324 rank=12\n",
            "[SoftImpute] Iter 30: observed MAE=0.032325 rank=12\n",
            "[SoftImpute] Iter 31: observed MAE=0.032325 rank=12\n",
            "[SoftImpute] Iter 32: observed MAE=0.032325 rank=12\n",
            "[SoftImpute] Iter 33: observed MAE=0.032325 rank=12\n",
            "[SoftImpute] Iter 34: observed MAE=0.032325 rank=12\n",
            "[SoftImpute] Stopped after iteration 34 for lambda=1.030921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzuO29beMKMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_mask = np.isnan(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rcvVuDoTqep",
        "colab_type": "text"
      },
      "source": [
        "Scikitlearn imputer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA2WATeQTmzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm_iey7TT9-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "082eab88-9de9-416b-ca29-0283277708c0"
      },
      "source": [
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imp_mean.fit(X)\n",
        "X_mean_filled = imp_mean.transform(X)\n",
        "print(X_mean_filled)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
            " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
            " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
            " ...\n",
            " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
            " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
            " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBApG_peUp8W",
        "colab_type": "text"
      },
      "source": [
        "Error Matrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8E1-SJnUG__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "6b4b289b-9cc3-42be-ba18-4f948dfa307f"
      },
      "source": [
        "# print mean squared error for the  imputation methods above\n",
        "nnm_mse = ((X_filled_nnm[missing_mask] - boston.data[missing_mask]) ** 2).mean()\n",
        "print(\"Nuclear norm minimization MSE: %f\" % nnm_mse)\n",
        "\n",
        "softImpute_mse = ((X_filled_softimpute[missing_mask] - boston.data[missing_mask]) ** 2).mean()\n",
        "print(\"SoftImpute MSE: %f\" % softImpute_mse)\n",
        "\n",
        "knn_mse = ((X_filled_knn[missing_mask] - boston.data[missing_mask]) ** 2).mean()\n",
        "print(\"knnImpute MSE: %f\" % knn_mse)\n",
        "\n",
        "simple_mean_mse = ((X_mean_filled[missing_mask] - boston.data[missing_mask]) ** 2).mean()\n",
        "print(\"Simple Mean Impute MSE: %f\" % simple_mean_mse)\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nuclear norm minimization MSE: 10850.010146\n",
            "SoftImpute MSE: 49625.567963\n",
            "knnImpute MSE: 128.216236\n",
            "Simple Mean Impute MSE: 327.665894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f8OxznGUkI3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS7S9HH-UiL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg0RiCqnUnxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "d065bc5e-fa67-423e-ef06-526be43cb0dc"
      },
      "source": [
        "fig,ax=plt.subplots(1,1)\n",
        "ax.plot(X_filled_nnm[missing_mask],\"o\",label='NNM filling')\n",
        "ax.plot(X_filled_softimpute[missing_mask],\"*\",label='Soft filling')\n",
        "ax.plot(X_filled_knn[missing_mask],\"<\",label='KNN filling')\n",
        "ax.plot(X_mean_filled[missing_mask],\"s\",label='Mean filling')\n",
        "ax.plot(boston.data[missing_mask],\"v\",label='actual')\n",
        "ax.legend(loc='best') # What is loc best"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f2345ef32b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRURcTkEvIuJy/x+gLli/usNi5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}